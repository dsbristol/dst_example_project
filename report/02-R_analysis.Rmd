---
title: "Example Assessment"
author: "Daniel Lawson"
date: "01/10/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# R part of assessment

## Header content

Required libraries:
```{r}
if (!require("tsne")) install.packages("tsne")
if (!require("network")) install.packages("network")
if (!require("sna")) install.packages("sna")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("GGally")) install.packages("GGally")
library("tsne")
library("fs") # for cross-platform directories
library(network) # For the final plot
library(sna) # For the final plot
library(ggplot2) # For the final plot
library("GGally") # For ggnet
library("knitr") # For kable 
```

Load the data:
```{r}
conndata=read.table(path_wd("..","data","processed","conn_sample.tab"),header=TRUE)
```

## Initial exploration

The first step is to examine the data using the *material given in class*. This starts with an examination of the protocol and service fields, which are likely to be very important types of information about the nature of the information flow.

```{r}
## Making a cyber table
cyber=table(conndata[,c("proto","service")])
kable(cyber)
```

Since we were asked to visualise it, we'll also plot the relative importance of each service, by protocol.
```{r}
## Barplot
#png("../media/02_EDA_barplot.png",height=500,width=800)
par(mfrow=c(1,3))
for(i in 1:dim(cyber)[1]) barplot(sort(cyber[i,],decreasing=T),
                                  main=rownames(cyber)[i],offset=0.1,
        log="y",col=rainbow(10),las=2)
#dev.off()
```
This makes the importance of the "missing" field very clear. Although we had available an image in the raw data, the best of all is the heatmap2 version:
```{r}
## gplots adds a scale and doesn't scale by default
library("gplots")
#png("../media/02_EDA_heatmap2.png",height=500,width=800)
heatmap.2(log(1+cyber),margins =c(9,15),trace="none")
#dev.off()
```
We can also make a fancy table with elements marked-up by content. This is an "interactive image" and can be argued to count as a visualisation. The data can be sorted by column which is helpful for exploration of the structure.
```{r}
## datatable creates HTML version of data
library(DT)
cuts=c(1,50,200,1000,10000)
colors=c("white", "lightblue","blue","magenta","purple","red")
datatable(t(unclass(cyber))) %>%
  formatStyle(columns = rownames(cyber), 
              background = styleInterval(cuts,colors))
## You have to screenshot it to get the image
## in the slides.
```
## Missingness

It is clear that missingness is a really important problem! So we'll start with an investigation of that:

```{r}
apply(conndata,2,function(x)mean(x=="-"))
```
It is clear that the missingness rate for some fieds is very high;1 for local_orig, and close to this for many other fields, especially service, duration, orig_bytes, resp_bytes. Many others are uninteresting as no data is missing.  

We have to do some work to examine missingness, because the content doesn't automatically do this. However, the code is the similar but run on different data. Lets visualise missingness as a heatmap:

```{r}
mdata=apply(conndata,2,function(x)(x=="-"))
allpresent=names(which(colMeans(mdata)==0))
allmissing=names(which(colMeans(mdata)==1))
somemissing=names(which(colMeans(mdata)>0 & colMeans(mdata)<1))
cormdata=cor(mdata[,somemissing])
heatmap.2(cormdata,cexRow=0.7,cexCol = 0.7,trace="none")
print(paste("all present:",paste(allpresent,collapse=",")))
print(paste("all missing:",paste(allmissing,collapse=",")))
print("correlation between the rest:")
cormdata
```
The heatmap is nice but in this case, looking at the values (see console window) is actually really important, because some of the fields are perfectly correlated in their missingness which the raw image doesn't clearly capture.

Missingness of history is anti-correlated with missingness of duration, orig_bytes and resp_bytes which are all perfectly correlated. Missingness of service is less correlated with anything.

### Durations
Now we wil investigate durations.  This code creates a histogram:
```{r}
## Histogram
tcpduration=conndata[conndata[,'proto']=="tcp",'duration']
tcpduration=tcpduration[tcpduration!="-"]
tcpduration=as.numeric(tcpduration)
#png("../media/02_EDA_historgram.png",height=500,width=800)
hist(log(tcpduration),breaks=20,probability=TRUE,col="red")
#dev.off()
```
The durations are weird, as the following table shows:
```{r}
matrix(head(sort(names(table(tcpduration))),12),
             nrow=3)
```
The problem here is that the data are rounded but weirdly, creating 3 possible values for each rounding. We might be better manually re-rounding to address this, if an analysis was sensitive to it.

The lectures gave a complicated and a simple way to generate "empirical survival curves", which are the proportion of events that are at least as long as $x$. There is no need to use the complicated one so we just report the simple:
```{r}
ports=conndata[,"id.orig_p"]
plot(ecdf(ports))
```
This is actually quite informative: it says that there are two main "clusters", one at lower values and the other at high values.

Of course the scatterplot is the go-to visualisation:
```{r}
## Scatterplot
conndata2=conndata[conndata[,"proto"]=="tcp",]
servicefactor=as.factor(conndata2[,'service'])
mycols=rainbow(length(levels(servicefactor)))
mycols[1]="#AAAAAAFF" # RRGGBBAA (Red Green Blue Alpha)
#png("../media/02_EDA_scatterplot.png",height=500,width=800)
plot(conndata2[,'orig_pkts'],conndata2[,'orig_ip_bytes'],
     log="xy",pch=4,col=mycols[servicefactor],
     xlab="Number of packets of data",ylab="Total amount of data")
legend("bottomright",legend=levels(servicefactor),text.col=mycols)
#dev.off()
```
This shows very clearly that there is a range of "data per packet" that seems strictly adhered to, though there is variability in this range. It looks by eye that the protocols are somewhat different in this measure.

## t-sne

The remit included an examination of other visualisation tools. We found a package, *t-sne*, that seems to be very popular so tried it on this data. It has been cited 5788 times (google scholar, Sept 2018) and has a very large number of online tutorials explaining what it is and why it is exciting. Unfortunately, most of these assume that you are working in Python but there is a perfectly good R implementation which we used.

```{r}
mytsne=tsne(dist(t(mdata)))
plot(mytsne)
```
It doesn't work at all as expected. This would be because the package doesn't give any clues about how to work with cyber-security data and cope with the weird properties it has.  We tried a few other things, including *scale* and *imputation of missing data* (see documentation; these are used below for something else) to get this to describe the relationship between the features, but this was unsuccessful. 

```{r}
conndataM=conndata
conndataM[conndataM[,8]=="-",8]="Missing"
for(i in c(9,10,11,16:19)) {
  conndataM[,i]=as.numeric(conndataM[,i])
  conndataM[is.na(conndataM[,i]),i]=0
}
for(i in c(7,8)) conndataM[,i]=as.factor(conndataM[,i])
mycols=c("id.orig_p","id.resp_p","duration","orig_bytes","resp_bytes","orig_pkts","orig_ip_bytes")
## Also better standardize
testdata=apply(conndataM[,mycols],2,scale)
```

Not to be defeated, we instead tried to use the package to visualse different records (instead of different fields). i.e. we switched from columns to rows. Unfortunately there were a lot of rows so we chose to examine a small subset.

```{r}
testpoints=testdata[sample(1:dim(testdata)[1],1000),]
testdist=dist(testpoints)
start_time <- Sys.time()
mytsne=tsne(testdist)
end_time <- Sys.time()
end_time - start_time
```
This was still quite slow but was fast enough to be used.

Plotting this required some thought. We got the idea from the documentation of "t-sne" package, but had to read about "?brewer.pal" to get the colors plotted nicely, so that we could see which features were associated with the location in the t-sne "embedding".
```{r}
library("RColorBrewer")
getcolor=function(x){
  colchart=seq(min(x),max(x),length.out=10)
  pal=brewer.pal(9,"RdPu")
  pal[sapply(x,function(y)min(which(colchart>=y))-1)]
}
par(mfrow=c(2,4))
for(i in 1:7) plot(mytsne,col=getcolor(testpoints[,i]),xlab="",ylab="",main=colnames(testpoints)[i])
```
The end results look cool but are probably not all that informative, in the sense that it doesn't appear that our t-sne has captured any of the variables in particular.

## Baloon plots and factor analysis

We used this resource:

http://www.sthda.com/english/articles/32-r-graphics-essentials/129-visualizing-multivariate-categorical-data/

to try out some sounding visualisations of our data. As always, it appears that the difficulty was making our cyber data look "not too crazy" so we started out by getting rid of all the rare "ports". This then got the number of factors we were dealing with into the same scale as that done in the example.

```{r}
ipportdf=conndataM[, c("id.orig_h","id.resp_p","service")]

porttab=table(ipportdf[,2])
commonports=names(porttab)[porttab>100]
ipportdf[!ipportdf[,2]%in%commonports,2]="other"

iptab=table(ipportdf[,1])
commonips=names(iptab)[iptab>100]
ipportdf[!ipportdf[,1]%in%commonips,1]="other"

ipport=as.data.frame(apply(ipportdf,2,as.factor))
mytab=table(ipport[,1:2])
```

We then tried the baloonplot and the "correspondance analysis biplot". However, we were not able to interpret those results (see documentation) and instead settled on a heatmap.

```{r}
heatmap.2(log(1+mytab),margins =c(9,15),trace="none")
```
This shows very clearly what each IP address is doing in terms of the ports it uses; eg there are some common ports that most machines use (to the left of the plot). Then some port that only a subset of machines use (top left, and the central bar across the top-middle), followed by some rare stuff that two machines neverless seem to use a lot.

We can do the same thing to compare ports with services:
```{r}
portservice=table(ipport[,2:3])
heatmap.2(log(1+portservice),margins =c(9,15),scale="none",trace="none")
```
Comparing ports with services at least allowed us to try the baloonplot example by making the data much smaller. This problem of scale makes baloonplots look unappealing for cyber data, but at least it looks nice here.

We first make a plotable dataframe and save it for later use.
```{r}
library("gplots")
# 1. convert the data as a table
# 2. Graph
portservice2=portservice[rowSums(portservice)>150,]
saveRDS(portservice2,file=path_wd("..","data","processed","portservice2.RDS"))
#write.table(as.matrix(portservice2),file=path_wd("..","data","processed","portservice2.tab"))
```

And make the plot:
```{r}
par(las=2)
balloonplot((log(1+portservice2)), main ="ports and services", xlab ="", ylab="",
            label = FALSE, show.margins = FALSE,text.size=0.5)
```
This seems very reassuring. Internet resources describe "TCP/IP ports" that match these ports (http://www.pearsonitcertification.com/articles/article.aspx?p=1868080). Wikipedia implies that different "protocols" to TCP use different ports (https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers) which explains why a large number of services use "other" ports. Presumably, this is also effected by the nature of the dataset - is it possible that some attacks that were used lie about the service that is running on a given port?

## Graph appraoches

There ar many graph approaches we could try, here is one:

https://briatte.github.io/ggnet/#example-2-bipartite-network

We tried it on IP information (see documentation) but got a hairball. Instead, we tried it on ports that are associated with at least one non-missing service.

```{r}
# set colors for each mode
col = c("actor" = "grey", "event" = "gold")

# weighted adjacency matrix
bipdata = as.matrix(portservice)[-1,-1] # Re
class(bipdata)="matrix"
bipdata=bipdata[rowSums(bipdata[,-5])>0,]
#bipdata[bipdata>0]=log(1+bipdata[bipdata>0])/10 # make it unweighted
#bipdata[bipdata<10]=0 #log(1+bipdata[bipdata>0])/10 # make it unweighted
bipdata[bipdata>0]=1

# weighted bipartite network
bip = network(bipdata,
              matrix.type = "bipartite",
              ignore.eval = FALSE,
              names.eval = "weights")

# detect and color the mode
ggnet2(bip, color = "mode", palette = col, label = TRUE,edge.size = "weights",layout.exp = 0.5,alpha = 0.75)
```

This gives an interesting map of the services, although only the "Missing" and "other" nodes are actually connected in a complex way.
